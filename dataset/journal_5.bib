@article{LI2022116027,
title = {One-shot neural architecture search for fault diagnosis using vibration signals},
journal = {Expert Systems with Applications},
volume = {190},
pages = {116027},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.116027},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421013737},
author = {Xudong Li and Jianhua Zheng and Mingtao Li and Wenzhen Ma and Yang Hu},
keywords = {Neural architecture search, Fault diagnosis, Vibration signals, One-shot model},
abstract = {Machine learning method has been widely applied in industrial fault diagnosis, especially the deep learning method. In the field of industrial fault diagnosis, deep learning is mostly used to extract features of vibration signals to achieve end-to-end fault diagnosis systems. Due to the complexity and variety of actual industrial datasets, some deep learning models are designed to be complicated. However, designing neural network architectures requires rich professional knowledge, experience, and a large number of experiments, increasing the difficulty of developing deep learning models. Fortunately, Neural Architecture Search (NAS), a branch of Automated Machine Learning (AutoML), is developing rapidly. Given a search space, NAS can search for networks that perform better than manually designed. In this paper, a one-shot NAS method for fault diagnosis is proposed. The one-shot model is a supernet that contains all candidate networks in a given search space. The supernet is trained to evaluate the actual performance of candidate networks by measuring the difference between its output probability and the true labels. According to the prediction of supernet, the networks with excellent performance can be searched, using some common search methods such as random search or evolutionary algorithm. Finally, the searched network is trained by reusing the weights of the supernet. To evaluate the proposed method, two search spaces are designed, ResNet and Inception search spaces, to search on PHM 2009 Data Challenge gearbox dataset. The state-of-the-art results are obtained, and accuracies of searched ResNet-A and Inception-A are 84.11% and 83.81%, which are 3.29% and 10.88% higher than Reinforcement Learning based NAS.}
}
@article{CHRISTENSEN2022116156,
title = {Principles for small-unit sUAS tactical deployment from a combat-simulating agent-based model analysis},
journal = {Expert Systems with Applications},
volume = {190},
pages = {116156},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.116156},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421014809},
author = {Carsten Christensen and John Salmon},
keywords = {Military decision-making processes, Unmanned system tactics, Agent-based modeling, Small unmanned aircraft systems},
abstract = {Recent increases in the operational and information gathering capabilities of small unmanned aircraft systems (sUAS) have made their deployment with small units of infantry attractive. Determining the potential impacts of sUAS deployment on infantry combat effectiveness and effectively disseminating that information to decision-making warfighters is imperative. This work presents an analysis of data generated by a Monte-Carlo simulation of 137,000 unique simulations of a static-defense scenario wherein defending units deploy sUAS in an information, surveillance, and reconnaissance role to aid in detecting, tracking, and targeting attacking units with indirect fires. The relationships between the number of UAVs deployed, the patrol method for those UAVs, and 40 combat effectiveness metrics are explored using a correlation matrix and other graphical methods. A set of eight principles for effective sUAs deployment in the aforementioned scenario are distilled from the simulation data and presented for further testing and validation.}
}
@article{ZHANG2022116048,
title = {Evaluation of a new dataset for visual detection of cervical precancerous lesions},
journal = {Expert Systems with Applications},
volume = {190},
pages = {116048},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.116048},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421013919},
author = {Ying Zhang and Yonit Zall and Ronen Nissim and  Satyam and Roger Zimmermann},
keywords = {Cervical cancer detection, Dataset, Deep learning, Transfer learning},
abstract = {Automated visual evaluation (AVE) is an emerging method to detect and diagnose cervical precancerous lesions by imaging and analysis via a deep learning classifier. Challenges in AVE development come from not only the limited data available, but also a proper design of the learning protocol. The most analyzed dataset (PEG) is traced to a clinical trial at a single site, where all the images were captured in a well controlled environment. Recently, cervical images have been captured by a light-weight mobile solution where the screening images were collected from a wider user pool at many sites. This paper introduces a new data resource (EVA dataset), collected by providers using a mobile colposcope during their routine practice. Compared to PEG, EVA images contain higher levels of data variations and exhibits a different distribution over multiple image attributes including image sharpness, brightness and colorfulness. In order to evaluate the practical value of EVA dataset for cervical high-grade squamous intraepithelial lesions (SIL) diagnosis, we further present an analysis of how a deep learning based framework can be used with both datasets by evaluating three key technical components: (1) region-of-interest (ROI) detection, (2) data augmentation and (3) pre-trained deep learning model selection. Our results indicate that ROI detection and shallow deep learning models usually help the detection on both datasets. While most data augmentations are effective on the EVA dataset, the improvement is less pronounced on PEG. Overall, using a deep-learning based framework looks promising for high-grade SIL diagnosis but there is still large room for improvements, especially on the EVA dataset. The noted differences indicate that the EVA dataset presents more practical challenges for high-grade SIL diagnosis and AVE classifier development.}
}
@article{KONOVALENKO2022116208,
title = {Generating decision support for alarm processing in cold supply chains using a hybrid k-NN algorithm},
journal = {Expert Systems with Applications},
volume = {190},
pages = {116208},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.116208},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421015220},
author = {Iurii Konovalenko and André Ludwig},
keywords = {k-nearest neighbors, Fuzzy set, Recommendation, Decision Support, Pharmaceutical supply chain, Temperature deviation},
abstract = {Real-time temperature monitoring is necessary in cold pharmaceutical supply chains (SCs), where exposures to extreme temperatures can lead to product quality deterioration. Temperature alarms (TAs) triggered by the current rule-based systems still require lengthy examinations before a suitable corrective measure (CM) can be chosen. However, provision of additional information relevant to TAs can expedite the examination process. In the related areas of recommender systems and false alarm/anomaly detection, k-nearest neighbors (k-NN) algorithm has proven to be successful because of its interpretability and ease of use. However, in the context of TA processing, it may suffer from some inherent limitations (i.e., varying neighborhood radius, unreliable classifications in sparse and noisy regions, and blindness to natural class boundaries). To overcome these limitations, we propose a hybrid k-NN (Hk-NN) algorithm based on the principles of local similarity and neighborhood homogeneity. It incorporates a two-step voting procedure with an entropy-optimized k-NN radius, decision trees with k-constrained leaves, and nearest neighbor predictions. We investigate 16,525 comments by alarm personnel for TAs in a pharmaceutical SC and encode them in terms of deviation causes and CMs (target features). We use SC data on cargo location, SC phase, sensor role, and temperature characteristics as predictor features for TA similarity estimation. In eight experimental setups, Hk-NN consistently outperforms k-NN with an optimized k in terms of accuracy, balanced accuracy, macro-average precision, recall, and specificity. At the same time, Hk-NN refrains from predicting observations, for which k-NN’s accuracy is close to a random guess.}
}
@article{JACKSON2022116223,
title = {Talk to The Ghost: The Storybox methodology for faster development of storytelling chatbots},
journal = {Expert Systems with Applications},
volume = {190},
pages = {116223},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.116223},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421015360},
author = {David Jackson and Annabel Latham},
keywords = {Chatbot, Intelligent interfaces, Storytelling, Response generation, Conversational agent, Human-computer conversation system},
abstract = {This paper presents the Storybox Methodology which combines a novel framework for structuring knowledge and conversations around a story (D-PAF), with a live chatroom-based training approach that builds the conversation knowledge base via live chatroom interactions. Chatbots have achieved success as intelligent interfaces in education, health, sales and support, but their move towards mainstream adoption has been hindered by the large amount of development resources required, in terms of data collection, preparation, user testing and technical knowledge. The complexity of the development task often necessitates both a system author and a domain expert working effectively together, adding further complexity and risk. Overcoming these barriers could increase feasibility of chatbots in a range of expert contexts. In education, there are groups of learners who do not enjoy reading and writing. Storytelling chatbots might be able to introduce these groups to enjoyable new ways to read and write, having a beneficial impact on their education and future prospects. This paper proposes the Storybox Methodology for the rapid development of storytelling chatbots. Storybox is evaluated by creating, training and testing ‘The Ghost’, a chatbot enacting Hamlet's Ghost character from William Shakespeare's dramatic tragedy. The results showed that after a period of live chatbot training of only 25 training conversations, The Ghost was able to conduct convincing conversations with participants.}
}
@article{KARA2022116198,
title = {The rise of ransomware: Forensic analysis for windows based ransomware attacks},
journal = {Expert Systems with Applications},
volume = {190},
pages = {116198},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.116198},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421015141},
author = {Ilker Kara and Murat Aydos},
keywords = {Cybersecurity, Digital forensic, Malware attacks, Ransomware detection, Onion ransomware, Analysis techniques},
abstract = {While information technologies grow and propagate worldwide, malwares have modified and risen their efficiency towards information system. Recently, the attackers have started to use ransom software (ransomware) as an effective method of cyberattack because of their profitability. Ransomware infiltrate victim systems in various ways, usually encrypt files in the system, and demand a ransom to allow user access to the encrypted files again. Although security mechanisms such as firewalls, anti-virus programs, and automated analysis programs have been developed to combat this threat, these mechanisms have little success and fail to protect the valuable assets stored in local or cloud storage resources. In this study, an effective detection and analysis method against ransomware was proposed, and the proposed method was discussed in detail with a case study. As a result of the study, potential information about the attacker were found to be accessible through characteristic behavior analysis of the onion ransomware, which was analyzed in accordance with the proposed method. This paper also presents an insight to the ransomware threat and provides a basic review of the methods and techniques used in the detection and analysis of ransomware attacks.}
}
@article{AGARWAL2022116154,
title = {Improvements in Multi-Document Abstractive Summarization using Multi Sentence Compression with Word Graph and Node Alignment},
journal = {Expert Systems with Applications},
volume = {190},
pages = {116154},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.116154},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421014792},
author = {Raksha Agarwal and Niladri Chatterjee},
keywords = {Multi-document abstraction, Word Graph, Node alignment, Multi sentence compression, Sentence fusion},
abstract = {The present work proposes a scheme for multi-document abstractive text summarization using node-aligned Word Graph based representation of clustered sentences. In the first step, the proposed scheme uses SBERT embedding for representing the sentences as fixed-size vectors. The sentences belonging to the same cluster are then represented using Word Graph, in which words of different sentences are aligned based on their semantic and syntactic similarities. The advantage of the above representation is that it utilizes alignment information of words between pairs of similar sentences to merge nodes in the Word Graph, and thereby facilitating the generation of sentences with multiple chunks of information. A sentence scoring function assisted by an intensification function is used to measure the grammaticality and informativeness of the generated sentences. Integer Linear Programming has been used to make the final selection of the scored sentences for generating the abstract. Experiments conducted for the task of sentence fusion and multi-document summarization demonstrate superior performance in comparison with the state-of-the-art techniques available in the literature.}
}
@article{MEI2022116165,
title = {Relation-aware Heterogeneous Graph Transformer based drug repurposing},
journal = {Expert Systems with Applications},
volume = {190},
pages = {116165},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.116165},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421014871},
author = {Xin Mei and Xiaoyan Cai and Libin Yang and Nanxin Wang},
keywords = {Drug repurposing, Graph neural network, Graph transformer, Link prediction, Heterogeneous network},
abstract = {Drug repurposing refers to discovery of new medical instructions for existing chemical drugs, which has great pharmaceutical significance. Recently, large-scale biological datasets are increasingly available, and many graph neural network (GNN) based methods for drug repurposing have been developed. These methods often deem drug repurposing as a link prediction problem, which mines features of biological data to identify drug–disease associations (i.e., drug–disease links). Due to heterogeneity of data, we need to deeply explore heterogeneous information of biological network for drug repurposing. In this paper, we propose a Relation-aware Heterogeneous Graph Transformer (RHGT) model to capture heterogeneous information for drug repurposing. We first construct a drug–gene–disease interactive network-based on biological data, and then propose a three-level network embedding model, which learns network embeddings at fine-grained subtype-level, node-level and coarse-grained edge-level, respectively. The output of subtype-level is the input of node-level and edge-level, and the output of node-level is the input of edge level. We get edge embeddings at edge-level, which integrates edge type embeddings and node embeddings. We deem that in this way, characteristics of drug–gene–disease interactive network can be captured more comprehensively. Finally, we identify drug–disease associations (i.e., drug–disease links) based on the relationship between drug–gene edge embeddings and gene–disease edge embeddings. Experimental results show that our model performs better than other state-of-the-art graph neural network methods, which validates effectiveness of the proposed model.}
}
@article{JOKIC2022116203,
title = {Semantic segmentation based stereo visual servoing of nonholonomic mobile robot in intelligent manufacturing environment},
journal = {Expert Systems with Applications},
volume = {190},
pages = {116203},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.116203},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421015189},
author = {Aleksandar Jokić and Milica Petrović and Zoran Miljković},
keywords = {Visual servoing, Semantic segmentation, Nonholonomic mobile robot, Image registration, Stereo camera system, Intelligent manufacturing systems},
abstract = {In the interest of developing an intelligent manufacturing environment with an agile, efficient, and optimally utilized transportation system, mobile robots need to achieve a certain level of autonomy as they play an important role in carrying out transportation tasks. Bearing this in mind, in the paper we propose a novel stereo visual servoing method for nonholonomic mobile robot control based on semantic segmentation. Semantic segmentation provides a rich body of information required for an adequate decision-making process in a clustered, dynamic, and ever-changing manufacturing environment. The innovative idea behind the new visual servoing system is to utilize semantic information of the scene for visual servoing, as well as for other mobile robot tasks, such as obstacle avoidance, scene understanding, and simultaneous localization and mapping. Semantic segmentation is carried out by exploiting fully convolutional neural networks. The new visual servoing algorithm utilizes an intensity-based image registration procedure, which results in the image transformation matrix. The transformation matrix encompasses the relations of images taken at the current and desired pose, and that information is directly used for visual servoing. The developed algorithm is deployed on our own developed wheeled differential drive mobile robot RAICO (Robot with Artificial Intelligence based COgnition). The experimental evaluation is carried out in the 3D simulation environment and in the laboratory model of the real manufacturing environment. The experimental results show that the accuracy of the proposed approach is improved when compared to the state-of-the-art approaches while being robust to the partial occlusions of the scene and illumination changes.}
}
@article{RADMAN2022115980,
title = {Deep residual network for face sketch synthesis},
journal = {Expert Systems with Applications},
volume = {190},
pages = {115980},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.115980},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421013300},
author = {Abduljalil Radman and Amer Sallam and Shahrel Azmin Suandi},
keywords = {Face sketch synthesis, Deep learning, Residual learning, Convolutional neural networks},
abstract = {Face sketch synthesis plays a crucial role in face recognition for law enforcement applications. However, the current face sketch synthesis approaches generate sketches from photos based on a model trained by a certain database that is usually collected from individuals of the same ethnicity, and therefore such sketches merely inherit distinct facial distributions (shape and texture) of this database. This also makes such models inapplicable for real-world applications which mainly include multiple photo variations such as pose, lighting, skin color, and ethnic origin. In this paper, a unified face sketch synthesis model considering ethnicity issue as well as photo variations is proposed. A new deep learning scheme is designed to handle the generic visual representation and global structure of the face. Towards the final objective, the recent success of deep residual blocks is exploited and incorporated into a plain feedforward network, termed as DResNet, to learn a regression model for face sketch synthesis. A heterogeneous database containing photos with lighting, ethnicity, hair and skin variations is utilized for training the DResNet model. Extensive subjective and objective evaluations showed the superiority of the proposed DResNet method on state-of-the-art face sketch synthesis methods. Experimental results also demonstrated that the proposed DResNet method can be generalized to face sketch synthesis for real-world applications.}
}
@article{TANEJA2022116106,
title = {An optimized scheme for energy efficient wireless communication via intelligent reflecting surfaces},
journal = {Expert Systems with Applications},
volume = {190},
pages = {116106},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.116106},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421014378},
author = {Ashu Taneja and Shalli Rani and Adi Alhudhaif and Deepika Koundal and Emine Selda Gündüz},
keywords = {Intelligent reflecting surfaces (IRSs), Energy efficiency (EE), Green communication, Optimization},
abstract = {Intelligent reflecting surfaces (IRSs) are considered as a promising candidate enabling technology for future green wireless communication. Such intelligent surfaces have real-time reconfigurable properties that beamform the signal to a desired destination. In this paper, our objective is to study the performance optimization in an IRS-assisted wireless network. An array of reflecting elements is individually configured in IRS system set up, which is installed between the source and the destination to assist the communication between both without any obstacle. IRS-assisted network achieves significant performance gain as compared to wireless networks without IRS. However, there are severe practical challenges with IRSs including hardware impairments, size of IRS, and distribution of reflecting elements in the IRS. To tackle these issues, we analyzed the performance of the network for maximum achievable rates, minimum transmit power, and maximum energy efficiency (EE). The selection of optimal number of reflecting elements in the IRS enables huge savings in energy to achieve target rate with minimal power. We show that by incorporating optimal number of reflecting elements in IRSs, high EE can be achieved, which outperforms the direct transmission method. Moreover, we show the impact of increasing the number of reflecting elements on the trade-off between EE and achievable rates.}
}
@article{S2022116168,
title = {Bag-of-Event-Models based embeddings for detecting anomalies in surveillance videos},
journal = {Expert Systems with Applications},
volume = {190},
pages = {116168},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.116168},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421014895},
author = {Chandrakala S. and Deepak K. and Vignesh L.K.P.},
keywords = {Surveillance videos, Anomaly detection, Bag-of-Event-Models, Motion Boundary Histograms, Hidden Markov Model, Support Vector Machine},
abstract = {Automated monitoring of unconstrained videos is becoming mandatory due to its widespread applications over public and private domains. Especially, research over detecting anomalous human behaviors in surveillance videos has created much attention. Understanding patterns in surveillance videos are always challenging due to the rapid movement of the crowd, occlusions, and cluttered backgrounds. The intra-class variations existing among normal and abnormal events lead to poor performance of anomaly detection system. These issues can be addressed by learning discriminative embeddings for video segments of surveillance videos. We propose an efficient Bag-of-Event-Models (BoEM) based embedding to represent video segments of normal and abnormal behaviors. Proposed BoEM can also be formed using training data of normal events only and the embeddings can be given as input to one-class classifier such as OC-SVM in an outlier detection fashion. The proposed embeddings handle intra-class variations and provide improved discrimination with much reduced dimension. Results over benchmark datasets namely Live Videos (LV), UCF-Crime and Crowd Violence demonstrate that the proposed BoEM based event embeddings in conjunction with SVM Classifier give significantly better performance than the other state-of-the-art methods. In addition, studies prove that the proposed embeddings are appropriate even for imbalanced sequential data such as video segments.}
}
@article{CANIZARES2022116149,
title = {SINPA: SupportINg the automation of construction PlAnning},
journal = {Expert Systems with Applications},
volume = {190},
pages = {116149},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.116149},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421014755},
author = {Pablo C. Cañizares and Sonia Estévez-Martín and Manuel Núñez},
keywords = {Constraint programming, Construction sites planning, Tools to support projects development},
abstract = {We present SINPA: an integrated framework to support construction site planners. The most basic functionality of our tool provides a user-friendly framework to represent causality relations (precedence and parallelism) between the different tasks conforming a project. SINPA strongly relies on a constraint solver and makes an intensive use of constraints. SINPA automatically studies optimisations of the original planning, recomputes the solutions and provides recommendations in an intuitive way so that the planners can modify their original plan. It is important to emphasise that the users of SINPA do not need to work with or understand Constraint Programming.}
}
@article{IMAMOVIC2022116185,
title = {Comprehensive fuzzy logic coefficient of performance of absorption cooling system},
journal = {Expert Systems with Applications},
volume = {190},
pages = {116185},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.116185},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421015049},
author = {Besim Imamović and Suad S. Halilčević and Pavlos S. Georgilakis},
keywords = {Absorption cooling system, Coefficient of performance, Fuzzy logic, Temperature, Mass flow rate, Concentration of solution},
abstract = {The Absorption Cooling System (ACS) coefficient of performance (COP) is a key parameter that describes the degree of efficiency of this type of cooling system. In all previous analyses, this coefficient was determined in a deterministic way, which in the case of the operation of a thermodynamic system, such as ACS, does not ensure its optimal operation. Therefore, in this paper, Comprehensive Fuzzy Logic COP (CFLCOP) is presented, which enables a more flexible operation of ACS and more precise action on those components of ACS that do not contribute to its optimal operation. The CFLCOP includes two fuzzy logic-based COPs: one based on energy efficiency (ENFLCOP) and the other on exergy efficiency (EXFLCOP). The analysis of the use of CFLCOP shows a higher number of hours of ACS operation in the optimal mode, compared to the deterministic COP (DCOP) and a higher degree of continuity of ACS operation at the desired cooling temperature.}
}
@article{DAOUI2022116193,
title = {Robust image encryption and zero-watermarking scheme using SCA and modified logistic map},
journal = {Expert Systems with Applications},
volume = {190},
pages = {116193},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.116193},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421015104},
author = {Achraf Daoui and Hicham Karmouni and Omar {El ogri} and Mhamed Sayyouri and Hassan Qjidaa},
keywords = {Image encryption, Image zero-watermarking, Geometric attacks, Image copyright protection, Logistic map, Modified logistic map},
abstract = {In this work, we first present a modified version of the traditional logistic chaotic map. The proposed version contains an additional parameter that is used to increase the security level of the proposed digital image copyright protection scheme. The latter merges two methods of image copyright protection, namely the image zero-watermarking and image encryption, which provides a high level of security when communicating images via the Internet. Next, we discuss the influence of geometric attacks on the efficiency of the proposed scheme, and then we introduce an efficient solution that can resist such attacks. The proposed solution involves the use of Sine Cosine Algorithm (SCA) with an appropriate algorithm suitable for the correction of geometric attacks (image translation, orientation and its combination) applied to the encrypted image. On the one hand, the simulation results show that the proposed scheme provides a high level of security and can resist various attacks (differential, common image processing, geometric, etc.). On the other hand, the conducted comparison in terms of robustness against geometric attacks clearly demonstrates the superiority of our scheme over recent image encryption ones.}
}
@article{ZHU2022116115,
title = {Static or dynamic? Characterize and forecast the evolution of urban crime distribution},
journal = {Expert Systems with Applications},
volume = {190},
pages = {116115},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.116115},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421014457},
author = {Qing Zhu and Fan Zhang and Shan Liu and Lin Wang and Shouyang Wang},
keywords = {Urban crime, Spatiotemporal framework, Crime distribution, Graph neural network},
abstract = {Despite the considerable deployed resources, current policing efforts are failing to stop crimes before they start, and therefore, also failing to adequately protect lives and property. To promote the intelligent transformation from reactive to proactive policing, this study proposed a hierarchical crime prediction framework. First, the temporal dependency in the frequency domain was decomposed and a network constructed to capture the spatial relationships within the sub-frequencies. Human mobility in a city was then utilized to characterize the dynamic relationships within the network. Using the proposed framework, this study examined the crime distribution evolution in Chicago to holistically predict the short-term crimes in the different communities. The framework was found to have high predictive accuracy and significant potential in promoting proactive policing. It was concluded that: (1) as the crime distribution evolution comes from the spatial relationship changes, these dynamic relationships are critical in explaining and characterizing the evolution; and (2) the social interactions constructed using the human activity data can characterize the dynamic crime distribution relationships.}
}
@article{XU2022116197,
title = {Zero-shot learning for compound fault diagnosis of bearings},
journal = {Expert Systems with Applications},
volume = {190},
pages = {116197},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.116197},
url = {https://www.sciencedirect.com/science/article/pii/S095741742101513X},
author = {Juan Xu and Long Zhou and Weihua Zhao and Yuqi Fan and Xu Ding and Xiaohui Yuan},
keywords = {Fault diagnosis, Zero-shot Learning, Compound fault diagnosis, Semantics},
abstract = {Due to the concurrency and coupling of various types of faults, and the number of possible fault modes grows exponentially, thereby compound fault diagnosis is a difficult problem in bearing fault diagnosis. The existing deep learning models can extract fault features when there are a large number of labeled compound fault samples. In industrial scenarios, collecting and labeling sufficient compound fault samples are unpractical. Using the model trained on single fault samples to identify unknown compound faults is challenging and innovative. To address this problem, we propose a Zero-shot Learning Compound Fault Diagnosis Model of bearings (ZLCFDM). We design an encoding method to express the semantics of single faults and compound faults according to the fault characteristics. A convolutional neural network is developed to extract the time–frequency features of the compound fault signal. Then we embed the semantic feature of the fault into the visual space of the fault data. The Euclidean distance is used to measure the distance between the signal features and the semantic features of the compound faults to identify the categories of unknown compound faults. To validate the proposed method, we conduct experiments on a self-built testbed. The results demonstrate that the accuracy of identifying compound fault reached 77.73% when the model was trained without any compound fault samples.}
}
@article{DESOUZA2022116180,
title = {Dynamic Programming algorithms and their applications in machine scheduling: A review},
journal = {Expert Systems with Applications},
volume = {190},
pages = {116180},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.116180},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421014998},
author = {Edson Antônio Gonçalves {de Souza} and Marcelo Seido Nagano and Gustavo Alencar Rolim},
keywords = {Scheduling, Dynamic Programming, Survey, Exact methods, FPTAS},
abstract = {This paper aims at presenting a compilation of state-of art references in which dynamic programming (DP) and its variants have been applied as a solution methods for the deterministic machine scheduling problems. Overall, 183 articles have been gathered and their segmentation was carried out according to the machine environment that characterized the problems addressed by the authors and ultimately, the objective functions that were intended to be optimized. Additionally, we standardized the information provided by each article by presenting the problems discussed by the authors, comparisons between previous works on the same problem (if it was deemed necessary), the algorithms’ complexities and an extension of methods to computational experiments (in case they have been stated). Finally, at the end of each section we furnish a discussion on the main contributions of DP to the each environment and also suggest some further applications of DP to machine scheduling problems, thus showing the potential resources that can be derived from the method in terms of theoretical/practical approaches.}
}
@article{KURANGA2022116163,
title = {A comparative study of nonlinear regression and autoregressive techniques in hybrid with particle swarm optimization for time-series forecasting},
journal = {Expert Systems with Applications},
volume = {190},
pages = {116163},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.116163},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421014858},
author = {C. Kuranga and N. Pillay},
keywords = {Time-series forecasting, Least-squares, Nonlinear autoregressive, Concept shifts, Passive learning, Quantum-inspired particle swarm optimization},
abstract = {Usually, real-world time-series forecasting problems are dynamic. If such time-series are characterized by mere concept shifts, a passive approach to learning become ideal to continuously adapt the model parameters whenever new data patterns arrive to cope with uncertainty in the presence of change. This work hybridizes a quantum-inspired particle swarm optimization designed for dynamic environments, to cope with concept shifts, with either a least-squares approximation technique or nonlinear autoregressive model to forecast time-series. Also, this work evaluates experimentally and performs a comparative study on the performance of the proposed models. The obtained results show that the nonlinear autoregressive-based model outperformed the least-squares approximation-based model and the separate models that were implemented in the hybridization and also, several state-of-the-art models for the given datasets.}
}
@article{LEE2022116206,
title = {Concept drift modeling for robust autonomous vehicle control systems in time-varying traffic environments},
journal = {Expert Systems with Applications},
volume = {190},
pages = {116206},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.116206},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421015207},
author = {Sangmin Lee and Sung Ho Park},
keywords = {Concept drift learning, Time-varying environments, Autonomous vehicle systems, Traffic control, Automated material handling systems},
abstract = {Autonomous vehicle systems (AVSs) are widely used to transfer wafers in semiconductor manufacturing. However, in such systems, robust traffic control is a significant challenge because all vehicles must be monitored and controlled in real time to cope with traffic congestion. Several predictive approaches have been proposed to prevent traffic congestion in stationary traffic environments. However, in real-life traffic situations, concept drifts exist, which are characterized by time-varying traffic conditions that hinder the accurate prediction of congestion. In this study, we propose a concept drift modeling framework for a robust vehicle control system. The proposed method combines a drift-adaptation learning technique with a drift detector to achieve adaptive traffic prediction in time-varying AVSs. We compare the effectiveness of the prediction and efficiency of model updates with representative methods. High-fidelity simulations based on actual data confirm that the proposed method outperforms alternative methods by detecting change patterns and updating prediction models whenever significant concept drifts occur in traffic patterns.}
}
@article{SHEIKHHOSSEINI2022116164,
title = {Connectivity and coverage constrained wireless sensor nodes deployment using steepest descent and genetic algorithms},
journal = {Expert Systems with Applications},
volume = {190},
pages = {116164},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.116164},
url = {https://www.sciencedirect.com/science/article/pii/S095741742101486X},
author = {Mohsen Sheikh-Hosseini and Seyed Rouhollah {Samareh Hashemi}},
keywords = {Connectivity, Coverage, Genetic algorithm, Steepest descent algorithm with Armijo and Wolf rules, Wireless sensor network (WSN)},
abstract = {Connectivity and different coverage types including target, area, and barrier coverages are among the most critical challenges of wireless sensor networks (WSN). This paper investigates node deployment for the challenges of target coverage, area coverage, and connectivity over randomly distributed homogeneous and heterogeneous WSNs, and suggests a new method in both centralized and distributed modes which (i) covers all targets by the required number of sensors, (ii) provides maximum area coverage and connectivity over the network, and (iii) manages sensors' movement from the initial locations to the final ones. Specifically, in the case of target coverage, a new analytical deployment method using the steepest descend (SD) algorithm with Armijo and Wolf rules is proposed instead of evolutionary methods. The results demonstrate this method outperforms over Genetic algorithm (GA) in managing sensors' movement towards targets, guaranteeing 100% coverage in targets, and providing a significant reduction- more than 40% in the worst condition-in algorithm complexity. However, when area coverage and connectivity are also considered, a new hybrid deployment method, which first uses GA to extract the optimal sensors' coordinates via analyzing these challenges simultaneously and then employs SD algorithm to move sensors towards these locations, is suggested. Numerical results confirm the complexity of this two-step method is approximately identical to the GA method of existing research; however, it provides sensors' trajectory and more accuracy for network coverage and connectivity.}
}
@article{ABDELBASSET2022116145,
title = {HWOA: A hybrid whale optimization algorithm with a novel local minima avoidance method for multi-level thresholding color image segmentation},
journal = {Expert Systems with Applications},
volume = {190},
pages = {116145},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.116145},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421014718},
author = {Mohamed Abdel-Basset and Reda Mohamed and Nabil M. AbdelAziz and Mohamed Abouhawwash},
keywords = {Color image segmentation, Whale optimization algorithm, Otsu method, Local minima elimination method, Multi-level thresholding},
abstract = {Traditional methods to address color image segmentation work efficiently for bi-level thresholding. However, for multi-level thresholding, traditional methods suffer from time complexity that increases exponentially with the increasing number of threshold levels. To overcome this problem, in this paper, a new approach is proposed to tackle multi-threshold color image segmentation by employing the Otsu method as an objective function. This approach is based on a hybrid of the whale optimization algorithm (WOA) with a novel method called the local minima avoidance method (LMAM), abbreviated as HWOA. LMAM avoids local minima by updating the whale either within the search space of the problem or between two whales selected randomly from the population-based on a certain probability. HWOA is validated on ten color images taken from the Berkeley University Dataset by measuring the objective values, peak signal-to-noise ratio (PSNR), structural similarity index (SSIM), features similarity index (FSIM), and CPU time, and compared with a number of the well-known robust meta-heuristic algorithms: the sine–cosine algorithm (SCA), WOA, modified salp swarm algorithm (MSSA), improved marine predators algorithm (IMPA), modified Cuckoo Search (CS) using McCulloch’s algorithm (CSMC), and equilibrium optimizer (EO). The experimental results show that HWOA is superior to all the other algorithms in terms of PSNR, FSIM, and objective values, and is competitive in terms of SSIM.}
}
@article{ZHANG2022116187,
title = {Tri-level attribute reduction in rough set theory},
journal = {Expert Systems with Applications},
volume = {190},
pages = {116187},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.116187},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421015050},
author = {Xianyong Zhang and Yiyu Yao},
keywords = {Attribute reduction, Three-way decision, Tri-level analysis, Object-specific attribute reducts, Tri-level attribute reducts, Granular computing},
abstract = {Attribute reduction serves as a pivotal topic of rough set theory for data analysis. The ideas of tri-level thinking from three-way decision can shed new light on three-level attribute reduction. Existing classification-specific and class-specific attribute reducts consider only macro-top and meso-middle levels. This paper introduces a micro-bottom level of object-specific reducts. The existing two types of reducts apply to the global classification with all objects and a local class with partial objects, respectively. The new type applies to an individual object. These three types of reducts constitute tri-level attribute reducts. Their development and hierarchy are worthy of systematical explorations. Firstly, object-specific reducts are defined by object consistency from dependency, and they improve both classification-specific and class-specific reducts. Secondly, tri-level reducts are unified by tri-level consistency. Hierarchical relationships between object-specific reducts and class-specific, classification-specific reducts are analyzed, and relevant connections of three-way classifications of attributes are given. Finally, tri-level reducts are systematically analyzed, and two approaches, i.e., the direct calculation and hierarchical transition, are suggested for constructing a specific reduct. We build a framework of tri-level thinking and analysis of attribute reduction to enrich three-way granular computing. Tri-level reducts lead to the sequential development and hierarchical deepening of attribute reduction, and their results profit intelligence processing and system reasoning.}
}
@article{COLAK2022116192,
title = {On the fly image denoising using patch ordering},
journal = {Expert Systems with Applications},
volume = {190},
pages = {116192},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.116192},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421015098},
author = {Ozden Colak and  {Ender M. Eksioglu}},
keywords = {Image denoising, Patch ordering, Online dictionary learning},
abstract = {We introduce an image denoising algorithm which utilizes a novel online dictionary learning procedure together with patch ordering. The developed algorithm employs both the non-local image processing power of patch ordering and the sequential patch-based update of online dictionary learning. The patch ordering process exploits the similarities between patches of a given image which are extracted from different locations. Joint processing of the ordered set of image patches facilitates the non-local image processing ability of the algorithm. The algorithm starts with the extraction of a maximally overlapped set of patches from the given noisy image. Then, the extracted patches are reordered by using a distance measure, and the 3D ordered patch cube is formed. The ordered patch cube is used sequentially to update an overcomplete dictionary. In each iteration, firstly the present patch is denoised using sparse coding over the current overcomplete dictionary. Secondly, the overcomplete dictionary is updated using the current image patch, and the dictionary is passed to the next iteration. We call this process as “on the fly denoising”, because each patch is individually denoised using an instantaneously updated overcomplete dictionary. Patch ordering together with online dictionary learning ensures that the dictionary is adapted to different neighborhoods of patches in the patch cube. This adaptation of the dictionary to specialized local patch structures in the patch cube promises improved denoising performance when compared to dictionary learning algorithms devoid of such adaptation. Simulation results indicate that the introduced online method presents improved denoising performance in comparison to both online and batch dictionary learning algorithms from the literature while maintaining similar computational complexity.}
}
@article{WANG2022116127,
title = {A novel predictive method based on key points for dynamic multi-objective optimization},
journal = {Expert Systems with Applications},
volume = {190},
pages = {116127},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.116127},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421014561},
author = {Chunfeng Wang and Gary G Yen and Fei Zou},
keywords = {Dynamic multi-objective optimization, TOPSIS, Clustering strategy, Predictive strategy},
abstract = {Dynamic multi-objective problem is very difficult to be solved because of the variability of the objective function with time. To overcome the difficult caused by such variability, a predictive method utilizing some key points (including polar points and centroid points) is designed, which contains four critical steps. First, the whole population is automatically divided into multiple clusters, which will be used to preserve a good diversity in the process of population evolution. Second, the technique for order of preference by similarity to ideal solution (TOPSIS), a well-regarded multi-attribute decision making strategy, is exploited to improve its convergence speed further. Third, the polar point and centroid point in each cluster are utilized to obtain the initial population by using sequence predictive method when environmental changes are detected. Fourth, to accelerate the convergence speed, the quantitative value for each individual determined in the prediction process is also used in mating selection and environmental selection. The numerical results imply that the new method can deal with the change of environment effectively and track the Pareto optimal front (POF) quickly. Meanwhile, the comparison results with several selected state-of-the-art methods also show that the overall performance of the proposed method is the best on most benchmark problems.}
}
@article{NASIRI2022116184,
title = {Robust control of congestion in computer networks: An adaptive fractional-order approach},
journal = {Expert Systems with Applications},
volume = {190},
pages = {116184},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.116184},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421015037},
author = {Iraj Nasiri and Nazila Nikdel},
keywords = {Congestion control, Fractional-order calculus, TCP/AQM network, Adaptive control, Asymptotic stability},
abstract = {In this study, the congestion problem of computer networks is solved by introducing an adaptive fractional-order controller. The controller is designed to enhance the efficiency of nonlinear transmission control protocol/active queue management (TCP/AQM) in these networks. External disturbances can perturb the data transmission. Moreover, factors such as undetermined link capacity can affect the congestion control problem. Hence, the proposed controller should guarantee robustness against disturbances and uncertainties. Besides, small elapsed time to reach the desired queue length as well as convergence of tracking error to zero are essential in queue management. These objectives are fulfilled by designing a fractional-order controller. High tracking capability and robustness make the controller an effective method for TCP/AQM networks. Furthermore, asymptotic stability of the network is precisely proven based on the fractional-order Lyapunov lemma. A variety of simulations are performed to examine capability of the proposed method confronting disturbances and uncertainties while providing a fast and stable response with zero tracking error. The results are also compared with the results of two recently developed control approaches for congestion problem, using performance indices, which confirm the efficiency and superiority of the introduced controller.}
}
@article{BHOWAL2022116167,
title = {Fuzzy ensemble of deep learning models using choquet fuzzy integral, coalition game and information theory for breast cancer histology classification},
journal = {Expert Systems with Applications},
volume = {190},
pages = {116167},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.116167},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421014883},
author = {Pratik Bhowal and Subhankar Sen and Juan D. Velasquez and Ram Sarkar},
keywords = {Breast cancer (BACH dataset), Computer vision, Deep learning, Fuzzy ensemble, Choquet integral, Coalition game, Information theory},
abstract = {Millions of women, worldwide, suffer from breast cancer and a large number of them succumb to death. In recent years, computer-aided diagnosis (CAD) systems are being developed for the detection of Breast Cancer. A number of fusion techniques have been proposed in this domain, but none of them take into consideration the decisions taken by a subset of classifiers during fusion. Our method, which uses Choquet Integral, considers subsets of classifiers and is thus stronger than the existing methods and beat all of these existing fusion methods in terms of accuracy. This however poses a significant challenge in terms of complexity, since the calculation of the fuzzy measures is a complicated and complex task, which we have dealt with using a novel heuristic method by employing Coalition Game, Information Theory, and by defining a novel mathematical function. In the present work, we have fused VGG16, VGG19, Xception, Inception V3, and InceptionResnet V2 for the classification of breast cancer histology images using a Choquet integral, Coalition game theory, and Information theory. The dataset used for evaluating the proposed model is the ICIAR 2018 Grand Challenge on Breast Cancer Histology (popularly known as BACH) images, which consist of 2-class and 4-class problems. To the best of our knowledge, our experimental results outperform almost all the state-of-the-art methods. For the two-class problem, the best test accuracy among the five deep learning models was achieved by Xception and it was 95% while the Fusion method has a test accuracy of 96%. For the four-class problem, Xception and InceptionResnet V2 have achieved the best test accuracy and both have a test accuracy of 91% while the Fusion method has a test accuracy of 95%. Again, in the case of the two-class problem the best precision and recall by the deep learning models are 0.95 and 0.95 respectively, while the precision and recall for after fusion are 0.96 and 0.96 respectively which is an increase of .01. In the case of the four-class problem, the best precision and recall by the deep learning models are 0.91 and 0.91 respectively, while the precision and recall after fusion are 0.95 and 0.95 respectively which is a very significant increase of .04. The source code for this project can be accessed at https://github.com/subhankar01/fuzzyBACH}
}
@article{QIAN2022116202,
title = {Financial distress prediction using a corrected feature selection measure and gradient boosted decision tree},
journal = {Expert Systems with Applications},
volume = {190},
pages = {116202},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.116202},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421015177},
author = {Hongyi Qian and Baohui Wang and Minghe Yuan and Songfeng Gao and You Song},
keywords = {Financial distress prediction, Gradient boosted decision tree, Feature importance, Permutation importance, Machine learning},
abstract = {Corporate financial distress prediction research has been ongoing for more than half a century, during which many models have emerged, among which ensemble learning algorithms are the most accurate. Most of the state-of-the-art methods of recent years are based on gradient boosted decision trees. However, most of them do not consider using feature importance for feature selection, and a few of them use the feature importance method with bias, which may not reflect the true importance of features. To solve this problem, a heuristic algorithm based on permutation importance (PIMP) is proposed to modify the biased feature importance measure in this paper. This method ranks and filters the features used by machine learning models, which not only improves accuracy but also makes the results more interpretable. Based on financial data from 4,167 listed companies in China between 2001 and 2019, the experiment shows that compared with using the random forest (RF) wrapper method alone, the bias in feature importance is indeed corrected by combining the PIMP method. After the redundant features are removed, the performance of most machine learning models is improved. The PIMP method is a promising addition to the existing financial distress prediction methods. Moreover, compared with traditional statistical learning models and other machine learning models, the proposed PIMP-XGBoost offers higher prediction accuracy and clearer interpretation, making it suitable for commercial use.}
}
@article{YANG2022116209,
title = {Semantic and explainable research-related recommendation system based on semi-supervised methodology using BERT and LDA models},
journal = {Expert Systems with Applications},
volume = {190},
pages = {116209},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.116209},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421015232},
author = {Nakyeong Yang and Jeongje Jo and Myeongjun Jeon and Wooju Kim and Juyoung Kang},
keywords = {Recommendation system, Semi-supervised learning, BERT, Explainable deep-learning},
abstract = {With the launch of academic search engines such as Google Scholar, Microsoft Academic, and Scopus, researchers are using them to access scholarly materials on a large scale without making any payment. In this optimal research environment, academic libraries or community databases have naturally experienced a rapid increase in volume; however, the excessive quantitative growth of information, or information overload, acts as a double-edged sword that prevents researchers from finding relevant prior studies or researchers with similar interests. Existing keyword and rule-based search systems carry the risk of recommending research literature with a high citation frequency rather than recommending contextually similar documents. Therefore, this study proposes a semi-supervised semantic-based research literature and researcher recommendation system using LDA and BERT. Since a semi-supervised method is used, research literature can be embedded based on contextual and classification information, and the global topic information of the research literature can also be captured. In addition, a research literature information extractor system has been implemented, which comprises classification network of our model and an explainable keywords extractor system implemented using BERT’s self-attention structure. Based on the experimental results, it can be confirmed that the proposed study model shows better performance than other baselines. This model can help users to find information and contextual matching data quickly and accurately from the database. In addition, when implementing an academic library and community database, such a powerful research-related recommendation system and research literature information extractor are expected to have an enormous effect.}
}
@article{FIDAN2022116243,
title = {A comparative study for determining Covid-19 risk levels by unsupervised machine learning methods},
journal = {Expert Systems with Applications},
volume = {190},
pages = {116243},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.116243},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421015530},
author = {Huseyin Fidan and Mehmet {Erkan Yuksel}},
keywords = {Covid-19, Risk levels, Restrictions, Unsupervised machine learning, Clustering, Gray relational clustering},
abstract = {The restrictions have been preferred by governments to reduce the spread of Covid-19 and to protect people's health according to regional risk levels. The risk levels of locations are determined due to threshold values ​​based on the number of cases per 100,000 people without environmental variables. The purpose of our study is to apply unsupervised machine learning techniques to determine the cities with similar risk levels by using the number of cases and environmental parameters. Hierarchical, partitional, soft, and gray relational clustering algorithms were applied to different datasets created with weekly the number of cases, population densities, average ages, and air pollution levels. Comparisons of the clustering algorithms were performed by using internal validation indexes, and the most successful method was identified. In the study, it was revealed that the most successful method in clustering based on the number of cases is Gray Relational Clustering. The results show that using the environmental variables for restrictions requires more clusters than 4 for healthier decisions and Gray Relational Clustering gives stable results, unlike other algorithms.}
}
@article{HU2022116031,
title = {MBRep: Motif-based representation learning in heterogeneous networks},
journal = {Expert Systems with Applications},
volume = {190},
pages = {116031},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.116031},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421013774},
author = {Qian Hu and Fan Lin and Beizhan Wang and Chunyan Li},
keywords = {Motif, Heterogeneous network, Representation learning, Cold-start},
abstract = {In recent years, there has been a surge of interest in applying machine learning to graphs and networks that already exist in the world around us. The approach has been successfully used for domains as diverse as traffic management, e-commerce recommendation and public opinion monitoring. A critical aspect of representation learning for applied machine learning is feature engineering. Deep learning-based research in representation learning has developed methods for automatically learning a large number of potentially correlated features from original networks. However, most of these methods cannot be applied to heterogeneous networks, which are true expressions of the real-world. This is because they do not adequately capture the structure and semantics of different types of nodes in heterogeneous networks and the links between them. They also struggle to represent higher-order heterogeneous patterns of connection. This paper proposes a generalized motif-based higher-order representation learning method, MBRep, that learns triangle motif embedding in a network, on the basis of which it can obtain the embedding and representation of nodes in a heterogeneous network. Statistically, significant motif structures are extracted from the original heterogeneous network and combined with the heterogeneity of the nodes. A weight-biased random walk is then applied to the motif level higher-order network, using a SkipGram model to embed the motifs. After this, the embedding of the original network nodes is calculated using weighted averages and feature alignment. This can then be used for link prediction. We confirmed the effectiveness of MBRep by comparing its AUC and MRR performance with other state-of-the-art methods on three real-world datasets. Its adaptability was also validated by conducting a cold-start test.}
}
@article{LIU2022116178,
title = {Gaussian-IoU loss: Better learning for bounding box regression on PCB component detection},
journal = {Expert Systems with Applications},
volume = {190},
pages = {116178},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.116178},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421014986},
author = {Xin Liu and Jinshuai Hu and Haixia Wang and Zhiguo Zhang and Xiao Lu and Chunyang Sheng and Shibin Song and Jun Nie},
keywords = {Object detection, PCB-components, Industrial inspection, Box regression, Gaussian IoU},
abstract = {Object detection with high accuracy is becoming increasingly important for industrial processes, such as producing printed circuit boards (PCBs). A false or missed detection during production can lead to serious quality issues. Therefore, an efficient detector that can maintain high quality is required for industrial applications. This paper proposes a method for improving detection accuracy while supporting real-time operations using the baseline YOLOv4. A new loss function for box regression called Gaussian intersection of union (GsIoU) is explored, which merges the predicted boxes under different anchors at the same position using a Gaussian function to calculate the box regression loss, improving the accuracy of the final box regression. The proposed PCB Component (PCBC) dataset is a benchmark comprising 18,948 images, 24 categories (containing the same component in different directions), and 508,313 components. Taking YOLOv4 as the experimental baseline on the PCBC dataset, the mean average precision (mAP) using the GsIoU has reached 86.9%, which is improved by 3.3% and 2.2% compared to using the CIoU and GIoU loss functions, respectively. The experiments were conducted on the COCO dataset to verify the generalization of the GsIoU. The detection accuracy of the GsIoU exceeds that GIoU and CIoU by 0.6% on AP50 and 0.6% on AP50:95, achieving 65.6% and 46.0% on the COCO test-val2017, respectively. The detection efficiency of the proposed method is the same as that of the baseline in the testing process and is slightly reduced in the training process owing to the synchronous calculation of the IoU, variance, and Gaussian operations on the network output. The experiments indicate that GsIoU is effective and efficient.}
}
@article{NAGAR2022116141,
title = {Adaptive optimal multi-features learning based representation for face hallucination},
journal = {Expert Systems with Applications},
volume = {190},
pages = {116141},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.116141},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421014688},
author = {Surendra Nagar and Ankush Jain and Pramod Kumar Singh and Ajay Kumar},
keywords = {Face hallucination, Multiple-image-features, GWO, Optimization, Gaussian noise, Thresholding},
abstract = {Face hallucination (FH) is a classical problem to reconstruct a high-resolution (HR) face image for an observed low-resolution (LR) one. The existing methods represent LR facial images though the spatial pixel domain or by combining confined image features with this spatial pixel information. However, the uncertainty in stipulating the optimal proportion for such multiple image features may lead to unexpected results as the optimal proportion for each LR input face image may vary for obtaining the desired HR result. Additionally, they suffer from degraded performance when the observed LR images are contaminated with higher noise. For addressing such problems, this paper proposes an adaptive optimal multi-features proportion learning (OMFPL) scheme, which adopts the Grey Wolf Optimization (GWO) approach for determining the optimum proportion of each feature to represent a particular LR face image. Moreover, an appropriate threshold is applied on different feature samples in the training data for representing the LR patches with their nearest examples. The optimal proportion of these relevant features helps to reconstruct the high-quality HR faces for both noise-free and noisy LR faces. The performance of OMFPL is validated on widely used public databases, real-world images, and surveillance faces, where it achieves the superior results concerning the several competitive state-of-the-art FH methods.}
}
@article{ZHOU2022116194,
title = {Cross-lingual embeddings with auxiliary topic models},
journal = {Expert Systems with Applications},
volume = {190},
pages = {116194},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.116194},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421015116},
author = {Dong Zhou and Xiaoya Peng and Lin Li and Jun-mei Han},
keywords = {Cross-lingual embeddings, Topical models, Word embedding models, Projection-based methods, Seed dictionaries},
abstract = {Projection-based methods for generating high-quality Cross-Lingual Embeddings (CLEs) have shown state-of-the-art performance in many multilingual applications. Supervised methods that rely on character-level information or unsupervised methods that need only monolingual information are both popular and have their pros and cons. However, there are still problems in terms of the quality of monolingual word embedding spaces and the generation of the seed dictionaries. In this work, we aim to generate effective CLEs with auxiliary Topic Models. We utilize both monolingual and bilingual topic models in the procedure of generating monolingual embedding spaces and seed dictionaries for projection. We present a comprehensive evaluation of our proposed model through the means of bilingual lexicon extraction, cross-lingual semantic word similarity and cross-lingual document classification tasks. We show that our proposed model outperforms existing supervised and unsupervised CLE models built on basic monolingual embedding spaces and seed dictionaries. It also exceeds CLE models generated from representative monolingual topical word embeddings.}
}
@article{LIU2022116216,
title = {Obstacle avoidance for orchard vehicle trinocular vision system based on coupling of geometric constraint and virtual force field method},
journal = {Expert Systems with Applications},
volume = {190},
pages = {116216},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.116216},
url = {https://www.sciencedirect.com/science/article/pii/S095741742101530X},
author = {Siyao Liu and Xiaoyan Wang and Sizhe Li and Xiangan Chen and Xuemin Zhang},
keywords = {Trinocular vision, Orchard vehicle, Row detection, Obstacle detection, Obstacle avoidance algorithm},
abstract = {Nowadays the use of visual navigation in orchard is rapidly growing, while current research mainly focuses on orchard row detection or obstacle detection separately. The economic, fast and reliable navigation vision system that completing orchard row following and obstacle avoidance simultaneously and the obstacle avoidance algorithm for vision system without complex multiple navigation systems combining are needed further research. In this paper, a trinocular vision system for orchard vehicle is set up and the obstacle avoidance algorithm based on coupling of geometric constraint and virtual force field is designed for its vision system. First of all, based on analyzing the different vision system characteristics and the detection demand of orchard obstacle avoidance the trinocular vision system for orchard vehicle is set up based on a wide-angle camera and binocular stereo vision system. Then, the image processing algorithm of orchard row and obstacle detection is designed. For orchard row detection, the trunk regions enhancement algorithm is designed based on grayscale morphology filtering the trunk regions prediction algorithm is designed based on optical flow method to improve the trunk regions detection speed and accuracy. For obstacle detection, the background equalization algorithm based on H-channel image characteristics and the interference weaken algorithm with G-channel image characteristics are designed. Based on the row and obstacle detection results the algorithm for obstacle avoidance in orchard based on coupling of geometric constraint and virtual force field is designed. In the obstacle avoidance process, the virtual force field method is used as the mainly control of the vehicle obstacle avoidance process, and the geometric constraint between visual model of trinocular vision system and obstacle position is coupling with it to fulfill the avoidance demand of the obstacle with special shape and other condition that influence the virtual force field calculation. The experimental results show that the trinocular vision system for orchard vehicle built in this paper has strong adaptability to the actual environment which is accurate and stable for orchard row detection and obstacle detection simultaneously. The average deviation is 4.76 cm and 7.05 cm at 0.5 m/s and 1.0 m/s respectively, the average deviation of obstacle distance detection in the Z-axis direction is 3.18 cm, and in the X-axis direction is 0.45 cm. And the obstacle avoidance algorithm designed in this paper is effective in the orchard which can meet the actual production requirements. The research results will lay a foundation for the development of intelligent equipment and unmanned management in orchard.}
}
@article{HOSSEINI2022116151,
title = {A hybrid greedy randomized heuristic for designing uncertain transport network layout},
journal = {Expert Systems with Applications},
volume = {190},
pages = {116151},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.116151},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421014767},
author = {Ahmad Hosseini and Eddie Wadbro},
keywords = {Operations research, Heuristics, Uncertain programming, Network design, Transportation},
abstract = {The foundations of efficient management are laid on transport networks in various scientific and industrial fields. Nonetheless, establishing an optimum transport network design (TND) is complicated due to uncertainty in the operating environment. As a result, an uncertain network may be a more realistic representation of an actual transport network. The present study deals with an uncertain TND problem in which uncertain programming and the greedy randomized adaptive search procedure (GRASP) are used to develop an original optimization framework and propose a solution technique for obtaining cost-efficient designs. To this end, we originally develop the concept of α-shortest cycle (α-SC) employing the pessimistic value criterion, given a user-defined predesignated confidence level α. Employing this concept and the operational law of uncertain programming, a new auxiliary chance-constrained programming model is established for the uncertain TND problem, and we prove the existence of an equivalence relation between TNDs in an uncertain network and those in an auxiliary deterministic network. Specifically, we articulate how to obtain the uncertainty distribution of the overall optimal uncertain network’s design cost. After all, the effectiveness and practical performance of the heuristic and optimization model is illustrated by adopting samples with different topology from a case study to show how our approach work in realistic networks and to highlight some of the heuristic’s features.}
}
@article{SHARMA2022116159,
title = {A framework for visual question answering with the integration of scene-text using PHOCs and fisher vectors},
journal = {Expert Systems with Applications},
volume = {190},
pages = {116159},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.116159},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421014822},
author = {Himanshu Sharma and Anand {Singh Jalal}},
keywords = {Computer vision, Dynamic pointer networks, PHOC, Fisher vector, Visual Question Answering (VQA)},
abstract = {Text contained in an image gives useful information about that image. Consider a warning signboard with text “high voltage”; it indicates the hazard or risk involved in the image. Thus, this semantic textual information can be very useful for better understanding of images, which is not utilized by the existing visual question answering (VQA) models. However, the presence of this textual information in images can strongly guide the VQA task. This work deal with the task of visual question answering by exploiting these textual cues together with the visual content to boost the accuracy of VQA models. In the work, a novel VQA model is proposed based on the PHOC and fisher vector based representation. Based on the PHOCs of the scene-text, we have constructed a powerful descriptor by using a Fisher Vectors. Also, the proposed model uses transformer model together with dynamic pointer networks for answer decoding process. Thus, the proposed model uses a sequence of decoding steps for answer generation instead of just assuming answer prediction as a classification problem as considered by previous works. We have shown the qualitative and quantitative results on three popular datasets: VQA 2.0, TextVQA and ST-VQA. The results show the effectiveness of the proposed model over the existing models.}
}
@article{SILVA2022116162,
title = {Modeling supply-chain networks with firm-to-firm wire transfers},
journal = {Expert Systems with Applications},
volume = {190},
pages = {116162},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.116162},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421014846},
author = {Thiago Christiano Silva and Diego Raphael Amancio and Benjamin Miranda Tabak},
keywords = {Networks, Firm trade networks, Wire transfers, Supply chains},
abstract = {We study a novel economic network (supply chain) comprised of wire transfers (electronic payment transactions) among the universe of firms in Brazil (6.2 million firms). We construct a directed and weighted network in which vertices represent cities and edges connote pairwise economic dependence between cities. Cities (vertices) represent the collection of all firms in that location, and links denote intercity wire transfers. We find a high degree of economic integration among cities in the trade network, consistent with the high degree of specialization across Brazilian cities. We identify cities with a dominant role as customers and suppliers to the entire supply chain using centrality network measures. The supply-chain network has a disassortative mixing pattern, which is explained by the heterogeneity in the size of Brazilian municipalities. We find that the supply-chain network becomes more disassortative during adverse times, such as the Brazilian recession in 2014 and the global financial crisis. We use entrepreneurship data and show that one potential driver of this change is the death of small firms, leading to a greater concentration of economic flows in larger centers. Our results suggest that adverse events significantly impact the supply-chain network with meaningful and heterogeneous economic consequences across municipalities. We run econometric exercises and find that courts’ efficiency plays a dual role. From the customer perspective, it may reduce contractual frictions and increase economic transactions between cities. From the supplier perspective, cities that are central suppliers to the supply chain may use courts’ inefficiency as a lawsuit barrier from their customers.}
}
@article{SOTO2022116169,
title = {Two novel branch and bound algorithms for the vertex bisection problem},
journal = {Expert Systems with Applications},
volume = {190},
pages = {116169},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.116169},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421014901},
author = {Carlos Soto and Eduardo Del Ángel-Martínez and Héctor Fraire-Huacuja and Bernabe Dorronsoro and Nelson Rangel and Laura Cruz-Reyes},
keywords = {Vertex bisection problem, B&B, Upper bound, Lower bound, Constructive heuristic},
abstract = {In this paper, we address the exact solution of the vertex bisection problem (VBP). We propose two novel B&B algorithms to solve VBP, which include new upper and lower bound constructive heuristics, and an efficient strategy to explore the combinatorial search space. The computational results show that the proposed algorithms clearly outperforms the state-of-the-art B&B algorithm in quality and efficiency. The two proposed B&B versions differ in the exploration strategy and the storage of the search tree. Also, we provide four new solutions, previously unknown. We consider that the main contributions of this work can be adapted to solve combinatorial problems in other related domains.}
}
@article{WANG2022116207,
title = {A fake review identification framework considering the suspicion degree of reviews with time burst characteristics},
journal = {Expert Systems with Applications},
volume = {190},
pages = {116207},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.116207},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421015219},
author = {Ning Wang and Jun Yang and Xuefeng Kong and Ying Gao},
keywords = {Fake review, Time series, Machine learning, Data and text mining, Doc2vec},
abstract = {With the rapid development of e-commerce, online reviews have played an increasingly important role in consumers' shopping intentions and behaviors. Therefore, how to effectively identify fake reviews has become one of the important issues that need to be resolved. Since the existing methods do not fully consider the time burst characteristics of reviews, this paper proposes a suspicion degree determining method based on the three-dimensional time series. Besides, combining the suspicion degree feature, review text features, and reviewer's behavior features together, this paper proposes a more comprehensive fake review identification framework. The yelp and amazon public data sets are carried out to verify the effectiveness of the proposed method, and the experimental results show that the proposed method outperforms the most advanced methods.}
}