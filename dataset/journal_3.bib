@article{TRIPATHI2022103303,
title = {MTCD: Cataract detection via near infrared eye images},
journal = {Computer Vision and Image Understanding},
volume = {214},
pages = {103303},
year = {2022},
issn = {1077-3142},
doi = {https://doi.org/10.1016/j.cviu.2021.103303},
url = {https://www.sciencedirect.com/science/article/pii/S1077314221001478},
author = {Pavani Tripathi and Yasmeena Akhter and Mahapara Khurshid and Aditya Lakra and Rohit Keshari and Mayank Vatsa and Richa Singh},
keywords = {Iris, Cataract, Biometrics, Classification, Deep learning, Multitask Learning},
abstract = {Globally, cataract is a common eye disease and one of the leading causes of blindness and vision impairment. The traditional process of detecting cataracts involves eye examination using a slit-lamp microscope or ophthalmoscope by an ophthalmologist, who checks for clouding of the normally clear lens of the eye. The lack of resources and unavailability of a sufficient number of experts pose a burden to the healthcare system throughout the world, and researchers are exploring the use of AI solutions for assisting the experts. Inspired by the progress in iris recognition, in this research, we present a novel algorithm for cataract detection using near-infrared eye images. The NIR cameras, which are popularly used in iris recognition, are of relatively low cost and easy to operate compared to ophthalmoscope setup for data capture. However, such NIR images have not been explored for cataract detection. We present deep learning-based eye segmentation and multitask network classification networks for cataract detection using NIR images as input. The proposed segmentation algorithm efficiently and effectively detects non-ideal eye boundaries and is cost-effective, and the classification network yields very high classification performance on the cataract dataset.}
}
@article{YU2022103314,
title = {HSGAN: Reducing mode collapse in GANs by the latent code distance of homogeneous samples},
journal = {Computer Vision and Image Understanding},
volume = {214},
pages = {103314},
year = {2022},
issn = {1077-3142},
doi = {https://doi.org/10.1016/j.cviu.2021.103314},
url = {https://www.sciencedirect.com/science/article/pii/S1077314221001570},
author = {Simin Yu and Kuntian Zhang and Chuan Xiao and Joshua Zhexue Huang and Mark Junjie Li and Makoto Onizuka},
keywords = {Generative adversarial networks, Mode collapse, Image generation},
abstract = {In this paper, we propose HSGAN, a novel generative adversarial network (GAN) variant that plays an adversarial game on the distance between two homogeneous samples (HS) in the latent space. HSGAN alleviates the notorious problem of mode collapse by maintaining a certain distance between the latent code of the generated data. Moreover, HSGAN is directly trained on the encoder and the generator, thereby gaining the ability to conduct inference without introducing any other model complexity. We prove theoretically that the objective function is designed to minimize the f-divergence between the distributions of the generated data and the real data. Extensive experiments on a series of synthetic and real image benchmark datasets demonstrate that HSGAN generates diverse images while keeping high quality, and it generally outperforms other GANs that target at the mode collapse problem.}
}
@article{AN2022103295,
title = {Deep structural information fusion for 3D object detection on LiDAR–camera system},
journal = {Computer Vision and Image Understanding},
volume = {214},
pages = {103295},
year = {2022},
issn = {1077-3142},
doi = {https://doi.org/10.1016/j.cviu.2021.103295},
url = {https://www.sciencedirect.com/science/article/pii/S1077314221001399},
author = {Pei An and Junxiong Liang and Kun Yu and Bin Fang and Jie Ma},
keywords = {3D object detection, LiDAR–camera system, Multi-sensor fusion},
abstract = {3D object detection on LiDAR–camera system is a challenging task, for 3D LiDAR point and 2D RGB image have different data representation. In this paper, We consider that the geometrical consistency in the local 3D and 2D regions is helpful for the regression task in 3D object detection, and propose 3D–2D consistent feature. It is based on hand-crafted 3D and 2D descriptors, generates primary structure feature, and has stable performance in outdoor scenes. Considering that material feature can be used to distinguish different objects, material coefficients ratio (MCR) is proposed to generate primary semantic feature, benefiting the classification task in 3D object detection. It is based on Lambertian model. To take advantage of both 3D–2D consistent feature and MCR, we propose deep 3D–2D structural information fusion (SIF) for 3D object detection. It provides attentional structural voxel feature, used as the input of LiDAR voxel based 3D object detectors. SIF is a light, effective, and explainable module. In the outdoor 3D object detection dataset, extensive experiments demonstrate that SIF improves the performance for both LiDAR voxel based single stage and multi-stage 3D detectors.}
}
@article{LI2022103301,
title = {Simultaneous multi-person tracking and activity recognition based on cohesive cluster search},
journal = {Computer Vision and Image Understanding},
volume = {214},
pages = {103301},
year = {2022},
issn = {1077-3142},
doi = {https://doi.org/10.1016/j.cviu.2021.103301},
url = {https://www.sciencedirect.com/science/article/pii/S1077314221001454},
author = {Wenbo Li and Yi Wei and Siwei Lyu and Ming-Ching Chang},
keywords = {Group activity, Collective activity recognition, Pairwise interaction, Multi-person tracking},
abstract = {We present a bootstrapping framework to simultaneously improve multi-person tracking and activity recognition at individual, interaction and social group activity levels. The inference consists of identifying trajectories of all pedestrian actors, individual activities, pairwise interactions, and collective activities, given the observed pedestrian detections. Our method uses a graphical model to represent and solve the joint tracking and recognition problems via three stages: (i) activity-aware tracking, (ii) joint interaction recognition and occlusion recovery, and (iii) collective activity recognition. This full-stack problem induces great complexity in learning the representations for the sub-problems at each stage, and the complexity increases as with more stages in the system. Our solution is to make use of symbolic cues for inference at higher stages, inspired by the observations of cohesive clusters at different stages. This also avoids learning more ambiguous representations in the higher stages. High-order correlations among the visible and occluded individuals, pairwise interactions, groups, and activities are then solved using the cohesive cluster search within a Bayesian framework. Experiments on several benchmarks show the advantages of our approach over the existing methods.}
}
@article{GONTHIER2022103299,
title = {Multiple instance learning on deep features for weakly supervised object detection with extreme domain shifts},
journal = {Computer Vision and Image Understanding},
volume = {214},
pages = {103299},
year = {2022},
issn = {1077-3142},
doi = {https://doi.org/10.1016/j.cviu.2021.103299},
url = {https://www.sciencedirect.com/science/article/pii/S1077314221001430},
author = {Nicolas Gonthier and Saïd Ladjal and Yann Gousseau},
keywords = {Deep learning, Convolutional neural networks, Weakly supervised object detection, Non-photographic images, Art analysis, Multiple instance learning},
abstract = {Weakly supervised object detection (WSOD) using only image-level annotations has attracted a growing attention over the past few years. Whereas such task is typically addressed with a domain-specific solution focused on natural images, we show that a simple multiple instance approach applied on pre-trained deep features yields excellent performances on non-photographic datasets, possibly including new classes. The approach does not include any fine-tuning or cross-domain learning and is therefore efficient and possibly applicable to arbitrary datasets and classes. We investigate several flavors of the proposed approach, some including multi-layers perceptron and polyhedral classifiers. Despite its simplicity, our method shows competitive results on a range of publicly available datasets, including paintings (People-Art, IconArt), watercolors, cliparts and comics and allows to quickly learn unseen visual categories.}
}